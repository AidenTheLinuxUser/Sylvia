#This code relies on the mechanize, beauitfulsoup, and requests library
#If you do not have these libraries, the code WILL NOT WORK 

import urllib
from bs4 import BeautifulSoup
import time
import requests
import socket
from contextlib import closing
import subprocess
import sys
from datetime import datetime


#Function to check if website is returning connection code
def checkAccess(request): 
	if request.status_code == 200:
		return True
	else: 
		return False


#Function to check indexing on a directory at the host name
def checkIndexing(host, dirToCheck): 
	requestPath = requests.get(host + "/" + dirToCheck + "/")
	readPath = urllib.urlopen(host + "/" + dirToCheck + "/").read().decode('utf-8')
	if requestPath.status_code == 200:
		if "Index of" in readPath: 
			print("VULNERABILITY - Indexing on /" + dirToCheck + "/")
	else: 
		print("/" + dirToCheck + "/" + " returning status code " + str(requestPath.status_code))
		
			

	
	





desc = "Sylvia Exploit Scanner BETA 1.0\nWritten by Aiden Calvert"

banner = "---------------------------------------------"

print(desc)
print(banner) 




#Selection for exploit scanning
if 1==1:
	#Opens instance of mechanize browser
	url = raw_input("\nEnter a URL or IP:\n> ")
	
	#Cuts out htp and https to where host is resolvable by ip checker 
	resolved = True 
	if url[:8] == "https://":
		urlIp = url[8:]
	elif url[:7] == "http://":
		urlIp = url[7:]
	else:
		resolved = False 
		urlIp = "Unresolvable"
	
	#Finds websites IP
	if resolved == False: 
		websiteIp = "Unresolvable"  
	else: 
		websiteIp = socket.gethostbyname(urlIp)
		
	print("\n")

	
	
	
	


	#Displays Info on target site/ip
	print(banner)
	print("IP: " + websiteIp)
	print("Hostname: " + url) 
	print(banner)

	


	time.sleep(1)


	print("Checking for SQL Injection...")


	#Opens site and adds single-quote to end of URL to check for SQLi
	try:
		checkCommaSQL =  urllib.request.urlopen(url + "'").read()
	except: 
		print("SAFE - No Browser SQLi Detected")
		checkCommaSQL = " " ;



	SQLERROR = "You have an error in your SQL syntax"

	#Checks for SQL Error string on page
	if SQLERROR in checkCommaSQL: 
		print("EXPLOIT - URL SQLi detected using single-quote on URL.")

	#Terminate if/else statement if SQLi check errored 
	elif checkCommaSQL == " ": 
		pass;
	
	else:
		print("No Browser SQLi detected.")

	time.sleep(1)


	print("Checking for Directory Indexing...") 

	#Check indexing on common directories
	
	checkIndexing(url, "img") 
	
	checkIndexing(url, "css")
	
	checkIndexing(url, "admin") 
	
		
	

	time.sleep(1) 

	print("Checking for CGI...") 

	time.sleep(1)



	#Sets conditional booleans and requests cgi-bin and sys
	requestCgiBin = requests.get(url + "/cgi-bin/")
	requestCgiSys = requests.get(url + "/cgi-sys/")

	cgiDetected = False
	cgiVuln = False



	#Checks if CGI-BIN 
	if requestCgiBin.status_code == 200 or requestCgiBin.status_code == 403: 
	
		print("CGI-BIN Detected and returning code " + str(requestCgiBin.status_code))
		cgiDetected = True
	
		requestHtmlScript = requests.get(url + "/cgi-bin/htmlscript")
	
		#Check for HTMLSCRIPT vulnerability on CGI
		if checkAccess(requestHtmlScript):
			print("CGI VULNERABILITY - HtmlScript found, this could be used for possible exploitation.")
			cgiVuln = True
	
		requestDumpEnv = requests.get(url + "/cgi-bin/dumpenv") 
		
		#Check for DumpEnv vulnerability
		if checkAccess(requestDumpEnv):
			print("CGI VULNERABILITY - DumpEnv found, can reveal info on server.")
			cgiVuln = True
		
		requestScriptDir = requests.get(url + "/cig-bin/scripts")
	
		#Check for /cgi-bin/scripts indexability
		if checkAccess(requestScriptDir):
			print("EXPLOIT - /cgi-bin/scripts/ may be indexable and/or readable!")
			cgiVuln = True
	
		requestCounter = requests.get(url + "/cgi-bin/counterfiglet/")
	
		if checkAccess(requestCounter): 
			print("CGI VULNERABILITY - CounterFiglet accessible, possible security vulnerability.")
	
	
	
	
	
	if cgiDetected == True and cgiVuln == False: 
		print("No CGI Vulnerabilities found on CGI-BIN.") 


	time.sleep(1)

	#Check CGI-SYS
	cgiVuln = False
	if requestCgiSys.status_code == 200 or requestCgiSys.status_code == 403: 
		print("CGI-SYS Detected and returning code " + str(requestCgiSys.status_code))
		cgiDetected = True 
		requestHtmlScript = requests.get(url + "/cgi-sys/htmlscript")
	
		#Check for HTMLSCRIPT vulnerability on CGI
		if checkAccess(requestHtmlScript):
			print("CGI VULNERABILITY - HtmlScript found, this could be used for possible exploitation.")
			cgiVuln = True
	
		requestDumpEnv = requests.get(url + "/cgi-sys/dumpenv") 
		
		#Check for DumpEnv vulnerability
		if checkAccess(requestDumpEnv):
			print("CGI VULNERABILITY - DumpEnv found, can reveal info on server.")
			cgiVuln = True
		
		requestScriptDir = requests.get(url + "/cgi-sys/scripts")
	
		#Check for /cgi-bin/scripts indexability
		if checkAccess(requestScriptDir):
			print("EXPLOIT - /cgi-sys/scripts/ may be indexable and/or readable!")
			cgiVuln = True
	
		requestCounter = requests.get(url + "/cgi-sys/counterfiglet/")
	
		if checkAccess(requestCounter): 
			print("CGI VULNERABILITY - CounterFiglet accessible, possible security vulnerability.")
			cgiVuln = True
	#Checks if any vulns have been detected 
	if cgiDetected == True and cgiVuln == False: 
		print("No CGI Vulnerabilities found on CGI-SYS.")
	
	#Checks if any CGI was detected, if not, it continues program
	if cgiDetected == False: 
		print("No CGI Detected. Skipping these steps.") 



requestRobotsTxt = requests.get(url + "/robots.txt") 


#Checks if robots.txt exists, and requests if user would like to see the contents
if checkAccess(requestRobotsTxt):
	viewRobots = raw_input("\nRobots TXT detected, scan for vulnerabilities?(Y/N)\n> ")
	if viewRobots == "Y" or viewRobots == "y": 
		print("Downloading robots.txt...")
		with open('robots.txt','wb') as f:
			f.write(urllib.urlopen(url + "/robots.txt").read())
			f.close()
		print("Download Complete.")
		
		with open('robots.txt', 'r') as f:
			first_line_robots = f.readline()
		
		robots = urllib.urlopen(url + "/robots.txt")
		readRobots = robots.read().decode('utf-8') 
		
		
		newString = readRobots.replace("Allow:", "")
		newString = newString.replace("Disallow:", "") 
		newString = newString.replace(first_line_robots, "")
		newString = newString.replace(" ", "") 
		
		
		tempList = [] 
		for char in newString: 
			linkCount = 0
			if char != "\n": 
				tempList.append(char)
			
			else: 
				tempDir = ''.join(tempList)
				if tempDir == "" or tempDir == " ": 
					break
				dirConnect = requests.get(url + tempDir) 
				print(tempDir + " returning status code " + str(dirConnect.status_code))
				tempList = [] 
			
					 
				
		
		



